{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_df = train[['merchant_id', 'mcc_id', 'settlement_period', 'working_type', 'merchant_segment']]\n",
    "# \n",
    "train = train[['merchant_id', 'month_id', 'net_payment_count']]\n",
    "train = train.sort_values(by=['merchant_id', 'month_id']).reset_index(drop=True)\n",
    "train['month_id'] = pd.to_datetime(train['month_id'], format='%Y%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_multiple_gaps(df, threshold):\n",
    "    # month_id sütununu datetime'a çevirme\n",
    "    \n",
    "    result_df = pd.DataFrame()  # Sonuçları saklamak için boş bir dataframe\n",
    "    \n",
    "    for merchant_id, group in df.groupby('merchant_id'):\n",
    "        group = group.sort_values(by='month_id')  # Her grubu tarihe göre sıralama\n",
    "        valid_indices = []  # Geçerli indeksleri saklamak için boş bir liste\n",
    "        \n",
    "        prev_date = None\n",
    "        for index, row in group.iterrows():\n",
    "            if prev_date is not None:\n",
    "                date_diff = (row['month_id'] - prev_date).days\n",
    "                if date_diff < threshold:\n",
    "                    # Eğer fark belirlenen eşikten küçükse, bu indeksi sakla\n",
    "                    valid_indices.append(index)\n",
    "                else:\n",
    "                    # Eşikten büyük bir fark bulunduğunda, geçerli indeksleri sıfırla ve bu indeksi ekle\n",
    "                    valid_indices = [index]\n",
    "            else:\n",
    "                # İlk satır her zaman geçerli olarak kabul edilir\n",
    "                valid_indices.append(index)\n",
    "            prev_date = row['month_id']\n",
    "        \n",
    "        # Geçerli indekslere sahip satırları sonuç DataFrame'ine ekle\n",
    "        result_df = pd.concat([result_df, group.loc[valid_indices]])\n",
    "    \n",
    "    return result_df.reset_index(drop=True)\n",
    "\n",
    "train = filter_by_multiple_gaps(train, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>month_id</th>\n",
       "      <th>net_payment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122846</th>\n",
       "      <td>merchant_37587</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122847</th>\n",
       "      <td>merchant_37587</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           merchant_id   month_id  net_payment_count\n",
       "122846  merchant_37587 2023-06-01                 10\n",
       "122847  merchant_37587 2023-07-01                 40"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['merchant_id'] == 'merchant_37587']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((65517, 3), (103043, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Son transaction ve ilk gözlem tarihlerini bulma\n",
    "last_transaction = train.groupby('merchant_id')['month_id'].max()\n",
    "first_observation = train.groupby('merchant_id')['month_id'].min()\n",
    "\n",
    "# Model DataFrames\n",
    "model_2020_df = train[train['merchant_id'].isin(first_observation[first_observation <= '2020-12-01'].index)]\n",
    "# model_2021_df = train[train['merchant_id'].isin(first_observation[(first_observation > '2020-09-01') & (first_observation <= '2022-09-01')].index)]\n",
    "# model_2022_df = train[train['merchant_id'].isin(first_observation[(first_observation > '2021-09-01') & (first_observation <= '2022-09-01')].index)]\n",
    "# model_2023_df = train[train['merchant_id'].isin(first_observation[first_observation > '2022-09-01'].index)]\n",
    "\n",
    "# Her merchant_id için gözlem sayısını say\n",
    "merchant_counts = model_2020_df['merchant_id'].value_counts()\n",
    "\n",
    "# Her merchant_id için en son gözlem tarihini bul\n",
    "last_observation = model_2020_df.groupby('merchant_id')['month_id'].max()\n",
    "\n",
    "# Gözlem sayısı 3'ten az olan veya son gözlem tarihi 202301'den düşük olan merchant_id'leri bul\n",
    "filtered_merchant_ids = merchant_counts[(last_observation <= '2023-06-01')].index\n",
    "# (merchant_counts <= 3) | \n",
    "\n",
    "# Bu merchant_id'leri no_model DataFrame'ine ata\n",
    "churn_df = model_2020_df[model_2020_df['merchant_id'].isin(filtered_merchant_ids)]\n",
    "\n",
    "# Diğer verileri updated_train DataFrame'ine ata\n",
    "model_2020_df = model_2020_df[~model_2020_df['merchant_id'].isin(filtered_merchant_ids)]\n",
    "\n",
    "# Set ve DataFrames'in boyutlarını kontrol etme\n",
    "churn_df.shape, model_2020_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# def detect_and_cap_outliers(df):\n",
    "#     df['rolling_mean'] = df['net_payment_count'].rolling(window=10, min_periods=1).mean()\n",
    "#     df['rolling_std'] = df['net_payment_count'].rolling(window=10, min_periods=1).std()  # ddof=0 for population std\n",
    "#     df['lower_limit'] = df['rolling_mean'] - 5 * df['rolling_std']\n",
    "#     df['upper_limit'] = df['rolling_mean'] + 5 * df['rolling_std']\n",
    "    \n",
    "#     # Aykırı değerleri tespit\n",
    "#     df['is_outlier'] = (df['net_payment_count'] < df['lower_limit']) | (df['net_payment_count'] > df['upper_limit'])\n",
    "    \n",
    "#     # Aykırı değerleri baskıla\n",
    "#     df['net_payment_count'] = np.where(df['net_payment_count'] < df['lower_limit'], df['lower_limit'],\n",
    "#                                               np.where(df['net_payment_count'] > df['upper_limit'], df['upper_limit'],\n",
    "#                                                        df['net_payment_count']))\n",
    "#     return df\n",
    "\n",
    "# # Her bir merchant_id için aykırı değerleri tespit etmek, baskılamak ve sonuçları görmek\n",
    "# merchant_ids = model_2020_df['merchant_id'].unique()\n",
    "# capped_results = []  # Sonuçları saklamak için boş bir liste\n",
    "\n",
    "# for merchant_id in merchant_ids:\n",
    "#     merchant_df = model_2020_df[model_2020_df['merchant_id'] == merchant_id].copy()\n",
    "#     capped_df = detect_and_cap_outliers(merchant_df)\n",
    "#     capped_results.append(capped_df)\n",
    "\n",
    "# # Sonuçların birleştirilmesi\n",
    "# model_2020_df = pd.concat(capped_results).reset_index(drop=True)\n",
    "# model_2020_df = model_2020_df[['merchant_id', 'month_id' ,'net_payment_count']]\n",
    "\n",
    "# # İlk birkaç sonucu göster\n",
    "# model_2020_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "753.0110051143697"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2020_df.net_payment_count.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((103043, 3), (0, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gözlem sayılarını hesaplama\n",
    "merchant_observation_counts = model_2020_df['merchant_id'].value_counts()\n",
    "\n",
    "# 11'den fazla gözlem içeren merchant'ları belirleme\n",
    "merchants_more_than_11 = merchant_observation_counts[merchant_observation_counts >= 0].index\n",
    "\n",
    "# 11'den az gözlem içeren merchant'ları belirleme\n",
    "merchants_less_than_11 = merchant_observation_counts[merchant_observation_counts < 0].index\n",
    "\n",
    "# Bu merchant'ların gözlemlerini ilgili DataFrame'lere ayırma\n",
    "model_2020_df_up = model_2020_df[model_2020_df['merchant_id'].isin(merchants_more_than_11)]\n",
    "model_2020_df_down = model_2020_df[model_2020_df['merchant_id'].isin(merchants_less_than_11)]\n",
    "\n",
    "# Sonuçların boyutlarını kontrol etme\n",
    "model_2020_df_up.shape, model_2020_df_down.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "merchant_id\n",
       "merchant_41252    45\n",
       "merchant_4046     45\n",
       "merchant_780      45\n",
       "merchant_41175    45\n",
       "merchant_7773     45\n",
       "                  ..\n",
       "merchant_35547    12\n",
       "merchant_27265    12\n",
       "merchant_52759    12\n",
       "merchant_26183    10\n",
       "merchant_10239    10\n",
       "Name: count, Length: 2736, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2020_df['merchant_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AZ GÖZLEMLİLERLE İLGİLEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>net_payment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202310merchant_10001</td>\n",
       "      <td>merchant_10001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202311merchant_10001</td>\n",
       "      <td>merchant_10001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202312merchant_10001</td>\n",
       "      <td>merchant_10001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202310merchant_10005</td>\n",
       "      <td>merchant_10005</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202311merchant_10005</td>\n",
       "      <td>merchant_10005</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202312merchant_10005</td>\n",
       "      <td>merchant_10005</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202310merchant_10008</td>\n",
       "      <td>merchant_10008</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202311merchant_10008</td>\n",
       "      <td>merchant_10008</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202312merchant_10008</td>\n",
       "      <td>merchant_10008</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202310merchant_10013</td>\n",
       "      <td>merchant_10013</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>202311merchant_10013</td>\n",
       "      <td>merchant_10013</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>202312merchant_10013</td>\n",
       "      <td>merchant_10013</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>202310merchant_10028</td>\n",
       "      <td>merchant_10028</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>202311merchant_10028</td>\n",
       "      <td>merchant_10028</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>202312merchant_10028</td>\n",
       "      <td>merchant_10028</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>202310merchant_10034</td>\n",
       "      <td>merchant_10034</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>202311merchant_10034</td>\n",
       "      <td>merchant_10034</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>202312merchant_10034</td>\n",
       "      <td>merchant_10034</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>202310merchant_10044</td>\n",
       "      <td>merchant_10044</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>202311merchant_10044</td>\n",
       "      <td>merchant_10044</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     merchant_id net_payment_count\n",
       "0   202310merchant_10001  merchant_10001              None\n",
       "1   202311merchant_10001  merchant_10001              None\n",
       "2   202312merchant_10001  merchant_10001              None\n",
       "3   202310merchant_10005  merchant_10005              None\n",
       "4   202311merchant_10005  merchant_10005              None\n",
       "5   202312merchant_10005  merchant_10005              None\n",
       "6   202310merchant_10008  merchant_10008              None\n",
       "7   202311merchant_10008  merchant_10008              None\n",
       "8   202312merchant_10008  merchant_10008              None\n",
       "9   202310merchant_10013  merchant_10013              None\n",
       "10  202311merchant_10013  merchant_10013              None\n",
       "11  202312merchant_10013  merchant_10013              None\n",
       "12  202310merchant_10028  merchant_10028              None\n",
       "13  202311merchant_10028  merchant_10028              None\n",
       "14  202312merchant_10028  merchant_10028              None\n",
       "15  202310merchant_10034  merchant_10034              None\n",
       "16  202311merchant_10034  merchant_10034              None\n",
       "17  202312merchant_10034  merchant_10034              None\n",
       "18  202310merchant_10044  merchant_10044              None\n",
       "19  202311merchant_10044  merchant_10044              None"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_merchant_ids = churn_df['merchant_id'].unique()\n",
    "\n",
    "# Her merchant_id için 2023-10, 2023-11, ve 2023-12 tarihleri için id oluştur\n",
    "submission_entries = []\n",
    "for merchant_id in unique_merchant_ids:\n",
    "    for month in ['10', '11', '12']:\n",
    "        submission_id = f'2023{month}{merchant_id}'\n",
    "        submission_entries.append([submission_id, merchant_id, None])\n",
    "\n",
    "# sub_no_model DataFrame'ini oluştur\n",
    "churn_2020 = pd.DataFrame(submission_entries, columns=['id', 'merchant_id', 'net_payment_count'])\n",
    "\n",
    "churn_2020.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>net_payment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202310merchant_10001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202311merchant_10001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202312merchant_10001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  net_payment_count\n",
       "0  202310merchant_10001                  0\n",
       "1  202311merchant_10001                  0\n",
       "2  202312merchant_10001                  0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_2020['net_payment_count'] = 0\n",
    "churn_2020 = churn_2020[['id', 'net_payment_count']]\n",
    "churn_2020.to_csv('churn_2020.csv', index=False)\n",
    "churn_2020.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filler(df):\n",
    "    # Define the target date\n",
    "    target_date = pd.to_datetime('2023-09-01')\n",
    "\n",
    "    # Find merchants that don't have a record on the target date\n",
    "    merchants_missing_target_date = df[~df['merchant_id'].isin(\n",
    "        df[df['month_id'] == target_date]['merchant_id']\n",
    "    )]['merchant_id'].unique()\n",
    "\n",
    "    # Get the first record of each merchant to preserve the static features\n",
    "    first_records_per_merchant = df[df['merchant_id'].isin(merchants_missing_target_date)].groupby('merchant_id').first().reset_index()\n",
    "\n",
    "    # Create missing records for the target date\n",
    "    missing_records = first_records_per_merchant.copy()\n",
    "    missing_records['month_id'] = target_date\n",
    "    missing_records['net_payment_count'] = 0\n",
    "\n",
    "    # Append the missing records to the original DataFrame\n",
    "    df = pd.concat([df, missing_records], ignore_index=True)\n",
    "\n",
    "    # Sort the updated DataFrame\n",
    "    df.sort_values(by=['merchant_id', 'month_id'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "model_2020_df_up = filler(model_2020_df_up) \n",
    "model_2020_df_down = filler(model_2020_df_down) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2021_df[model_2021_df['merchant_id'] == 'merchant_55336']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2021_df['merchant_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2020_df = model_2020_df[model_2020_df['month_id'] > '2020-12-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_features_df = static_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "\n",
    "# model_2020_df_down_data = TimeSeriesDataFrame.from_data_frame(\n",
    "#     model_2020_df_down,\n",
    "#     id_column=\"merchant_id\",\n",
    "#     timestamp_column=\"month_id\",\n",
    "#     static_features_df=static_features_df\n",
    "# )\n",
    "# model_2020_df_down_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2020_df_down_data = model_2020_df_down_data.convert_frequency(freq=\"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2020_df_down_data['net_payment_count'] = model_2020_df_down_data['net_payment_count'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2020_df_down_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from autogluon.common import space\n",
    "\n",
    "# predictor = TimeSeriesPredictor(\n",
    "#     prediction_length=3,\n",
    "#     target=\"net_payment_count\",\n",
    "#     eval_metric=\"MAE\",\n",
    "#     freq='M',\n",
    "#     quantile_levels=[0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.6, 0.7],\n",
    "# #     known_covariates_names=[\"month\", \"year\"]\n",
    "# )\n",
    "\n",
    "# predictor.fit(\n",
    "#     model_2020_df_down_data,\n",
    "#     presets=\"best_quality\",\n",
    "#     time_limit= 3600 * 6,\n",
    "#     # excluded_model_types=[\"TemporalFusionTransformer\", \"DeepAR\"],\n",
    "    \n",
    "#     hyperparameters={\n",
    "# #     #   \"SeasonalNaive\": {\"n_jobs\": -1},\n",
    "# #       \"Naive\": {\"n_jobs\": 6},\n",
    "# #       \"AutoETS\": {\"n_jobs\": 6},\n",
    "# #       \"DynamicOptimizedTheta\": {\"n_jobs\": 6},\n",
    "# #       \"RecursiveTabular\": {\"n_jobs\": 6},\n",
    "# #       \"AutoCES\": {\"n_jobs\": 6},\n",
    "# # #       \"ADIDA\": {},\n",
    "# # #       \"IMAPA\": {},\n",
    "# # #       \"DLinear\": {},\n",
    "# # #       \"SimpleFeedForward\": {},\n",
    "#       \"DeepAR\": {\"n_jobs\": 6},\n",
    "#       \"PatchTST\": {\"n_jobs\": 6},\n",
    "#         },\n",
    "# #     hyperparameter_tune_kwargs={\n",
    "# # #     \"num_trials\": 5,\n",
    "# # #     \"scheduler\": \"local\",\n",
    "# # #     \"searcher\": \"random\",\n",
    "# #     \"n_jobs\": -1\n",
    "# # },\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = predictor.predict(model_2020_df_down_data, model='WeightedEnsemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = predictions.copy().reset_index()\n",
    "# results['id'] = results['timestamp'].dt.strftime('%Y%m') + results['item_id']\n",
    "\n",
    "# # Select the 'id' and 'mean' columns and rename 'mean' to 'net_payment_count'\n",
    "# model_2020_down_sub = results[['id', '0.5']].rename(columns={'0.5': 'net_payment_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2020_down_sub.to_csv('model_2020_down_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_features_df = static_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>net_payment_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">merchant_10057</th>\n",
       "      <th>2020-06-01</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-01</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-01</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-01</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           net_payment_count\n",
       "item_id        timestamp                    \n",
       "merchant_10057 2020-06-01                  3\n",
       "               2021-01-01                  4\n",
       "               2021-02-01                  6\n",
       "               2021-03-01                  4\n",
       "               2021-04-01                  3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "\n",
    "model_2020_df_up_data = TimeSeriesDataFrame.from_data_frame(\n",
    "    model_2020_df_up,\n",
    "    id_column=\"merchant_id\",\n",
    "    timestamp_column=\"month_id\",\n",
    "    static_features_df=static_features_df\n",
    ")\n",
    "model_2020_df_up_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>net_payment_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">merchant_10057</th>\n",
       "      <th>2020-06-30</th>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-31</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-31</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-31</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           net_payment_count\n",
       "item_id        timestamp                    \n",
       "merchant_10057 2020-06-30              3.000\n",
       "               2020-07-31              0.000\n",
       "               2020-08-31              0.000\n",
       "               2020-09-30              0.000\n",
       "               2020-10-31              0.000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2020_df_up_data = model_2020_df_up_data.convert_frequency(freq=\"M\")\n",
    "model_2020_df_up_data['net_payment_count'] = model_2020_df_up_data['net_payment_count'].fillna(0)\n",
    "model_2020_df_up_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-01-01                                       New Year's Day\n",
       "2020-04-23              National Sovereignty and Children's Day\n",
       "2020-05-01                                           Labour Day\n",
       "2020-05-19       Commemoration of Ataturk, Youth and Sports Day\n",
       "2020-05-24                                        Ramadan Feast\n",
       "2020-05-25                                Ramadan Feast Holiday\n",
       "2020-05-26                                Ramadan Feast Holiday\n",
       "2020-07-15                     Democracy and National Unity Day\n",
       "2020-07-31                                      Sacrifice Feast\n",
       "2020-08-01                              Sacrifice Feast Holiday\n",
       "2020-08-02                              Sacrifice Feast Holiday\n",
       "2020-08-03                              Sacrifice Feast Holiday\n",
       "2020-08-30                                          Victory Day\n",
       "2020-10-29                                         Republic Day\n",
       "2021-01-01                                       New Year's Day\n",
       "2021-04-23              National Sovereignty and Children's Day\n",
       "2021-05-01                                           Labour Day\n",
       "2021-05-13                                        Ramadan Feast\n",
       "2021-05-14                                Ramadan Feast Holiday\n",
       "2021-05-15                                Ramadan Feast Holiday\n",
       "2021-05-19       Commemoration of Ataturk, Youth and Sports Day\n",
       "2021-07-15                     Democracy and National Unity Day\n",
       "2021-07-20                                      Sacrifice Feast\n",
       "2021-07-21                              Sacrifice Feast Holiday\n",
       "2021-07-22                              Sacrifice Feast Holiday\n",
       "2021-07-23                              Sacrifice Feast Holiday\n",
       "2021-08-30                                          Victory Day\n",
       "2021-10-29                                         Republic Day\n",
       "2022-01-01                                       New Year's Day\n",
       "2022-04-23              National Sovereignty and Children's Day\n",
       "2022-05-01                                           Labour Day\n",
       "2022-05-02                                        Ramadan Feast\n",
       "2022-05-03                                Ramadan Feast Holiday\n",
       "2022-05-04                                Ramadan Feast Holiday\n",
       "2022-05-19       Commemoration of Ataturk, Youth and Sports Day\n",
       "2022-07-09                                      Sacrifice Feast\n",
       "2022-07-10                              Sacrifice Feast Holiday\n",
       "2022-07-11                              Sacrifice Feast Holiday\n",
       "2022-07-12                              Sacrifice Feast Holiday\n",
       "2022-07-15                     Democracy and National Unity Day\n",
       "2022-08-30                                          Victory Day\n",
       "2022-10-29                                         Republic Day\n",
       "2023-01-01                                       New Year's Day\n",
       "2023-04-21                                        Ramadan Feast\n",
       "2023-04-22                                Ramadan Feast Holiday\n",
       "2023-04-23    National Sovereignty and Children's Day; Ramad...\n",
       "2023-05-01                                           Labour Day\n",
       "2023-05-19       Commemoration of Ataturk, Youth and Sports Day\n",
       "2023-06-28                                      Sacrifice Feast\n",
       "2023-06-29                              Sacrifice Feast Holiday\n",
       "2023-06-30                              Sacrifice Feast Holiday\n",
       "2023-07-01                              Sacrifice Feast Holiday\n",
       "2023-07-15                     Democracy and National Unity Day\n",
       "2023-08-30                                          Victory Day\n",
       "2023-10-29                                         Republic Day\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import holidays\n",
    "\n",
    "timestamps = model_2020_df_up_data.index.get_level_values(\"timestamp\")\n",
    "country_holidays = holidays.country_holidays(\n",
    "    country=\"TR\",\n",
    "    years=range(timestamps.min().year, timestamps.max().year + 1),\n",
    ")\n",
    "pd.Series(country_holidays).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    datetime.date(2020, 4, 1): \"Corona\",\\n    datetime.date(2020, 5, 1): \"Corona\",\\n    datetime.date(2020, 6, 1): \"Corona\",\\n    # datetime.date(2021, 4, 1): \"Corona\",\\n    # datetime.date(2021, 5, 1): \"Corona\",\\n    datetime.date(2023, 3, 1): \"Deprem\", Minimum degerlerden biri buraya tekabul ediyor\\n    datetime.date(2023, 5, 1): \"Secim\",\\n    datetime.date(2023, 6, 1): \"Secim\",\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "# Yukarıda bahsettiğim grafikteki minimum-maksimum değerleri:\n",
    "custom_dates = {\n",
    "    datetime.date(2021, 1, 1): \"Lowest\",\n",
    "    datetime.date(2021, 5, 1): \"Highest\",\n",
    "    datetime.date(2021, 7, 1): \"Lowest\",\n",
    "    datetime.date(2021, 11, 1): \"Highest\",\n",
    "    datetime.date(2022, 1, 1): \"Lowest\",\n",
    "    datetime.date(2023, 3, 1): \"Lowest\",\n",
    "}\n",
    "'''\n",
    "    datetime.date(2020, 4, 1): \"Corona\",\n",
    "    datetime.date(2020, 5, 1): \"Corona\",\n",
    "    datetime.date(2020, 6, 1): \"Corona\",\n",
    "    # datetime.date(2021, 4, 1): \"Corona\",\n",
    "    # datetime.date(2021, 5, 1): \"Corona\",\n",
    "    datetime.date(2023, 3, 1): \"Deprem\", Minimum degerlerden biri buraya tekabul ediyor\n",
    "    datetime.date(2023, 5, 1): \"Secim\",\n",
    "    datetime.date(2023, 6, 1): \"Secim\",\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dates = country_holidays.copy()\n",
    "for date, event in custom_dates.items():\n",
    "    if date in merged_dates:\n",
    "        merged_dates[date] += \", \" + event\n",
    "    else:\n",
    "        merged_dates[date] = event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date_features(\n",
    "    ts_df: TimeSeriesDataFrame, \n",
    "    country_holidays: dict,\n",
    "    include_individual_holidays: bool = True,\n",
    "    include_holiday_indicator: bool = True,\n",
    ") -> TimeSeriesDataFrame:\n",
    "    \"\"\"Tatil günleri ve bahsedilen maksimum-minimum degerleri ekle\"\"\"\n",
    "    ts_df = ts_df.copy()\n",
    "    timestamps = ts_df.index.get_level_values(\"timestamp\")\n",
    "    country_holidays_df = pd.get_dummies(pd.Series(country_holidays)).astype(float)\n",
    "    holidays_df = country_holidays_df.reindex(timestamps.date).fillna(0)\n",
    "    if include_individual_holidays:\n",
    "        ts_df[holidays_df.columns] = holidays_df.values\n",
    "    if include_holiday_indicator:\n",
    "        ts_df[\"Holiday\"] = holidays_df.max(axis=1).values\n",
    "    return ts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2020_df_up_data = add_date_features(model_2020_df_up_data, merged_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_columns = model_2020_df_up_data.columns.to_list()\n",
    "holiday_columns.remove('net_payment_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training... Time limit = 21600s\n",
      "AutoGluon will save models to 'AutogluonModels\\ag-20240227_185725'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       6.43 GB / 15.42 GB (41.7%)\n",
      "Disk Space Avail:   71.79 GB / 476.34 GB (15.1%)\n",
      "===================================================\n",
      "Setting presets to: best_quality\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': MAE,\n",
      " 'freq': 'M',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 4,\n",
      " 'prediction_length': 3,\n",
      " 'quantile_levels': [0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.4, 0.5],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': True,\n",
      " 'target': 'net_payment_count',\n",
      " 'time_limit': 21600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 113842 rows, 2736 time series. Median time series length is 43 (min=34, max=45). \n",
      "\n",
      "Provided dataset contains following columns:\n",
      "\ttarget:           'net_payment_count'\n",
      "\tpast covariates:  ['Commemoration of Ataturk, Youth and Sports Day', 'Democracy and National Unity Day', 'Highest', 'Labour Day', 'Labour Day; Labour Day, Highest', 'Lowest', \"National Sovereignty and Children's Day\", \"National Sovereignty and Children's Day; Ramadan Feast Holiday\", \"New Year's Day\", \"New Year's Day; New Year's Day, Lowest\", 'Ramadan Feast', 'Ramadan Feast Holiday', 'Republic Day', 'Sacrifice Feast', 'Sacrifice Feast Holiday', 'Victory Day', 'Holiday']\n",
      "Following types of static features have been inferred:\n",
      "\tcategorical:        ['mcc_id', 'settlement_period', 'working_type', 'merchant_segment']\n",
      "\tcontinuous (float): []\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit \n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MAE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2024-02-27 21:57:29\n",
      "Models that will be trained: ['SeasonalNaive', 'CrostonSBA', 'NPTS', 'AutoETS', 'DynamicOptimizedTheta', 'AutoARIMA', 'RecursiveTabular', 'DirectTabular', 'DeepAR', 'TemporalFusionTransformer', 'PatchTST']\n",
      "Training timeseries model SeasonalNaive. Training for up to 1908.5s of the 21593.8s of remaining time.\n",
      "\t-376.6759     = Validation score (-MAE)\n",
      "\t8.34    s     = Training runtime\n",
      "\t1.27    s     = Validation (prediction) runtime\n",
      "Training timeseries model CrostonSBA. Training for up to 2098.4s of the 21584.1s of remaining time.\n",
      "\t-346.8869     = Validation score (-MAE)\n",
      "\t13.70   s     = Training runtime\n",
      "\t1.68    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 2329.9s of the 21568.7s of remaining time.\n",
      "\t-507.9196     = Validation score (-MAE)\n",
      "\t7.04    s     = Training runtime\n",
      "\t2.00    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 2620.0s of the 21559.7s of remaining time.\n",
      "\t-282.9444     = Validation score (-MAE)\n",
      "\t107.64  s     = Training runtime\n",
      "\t28.71   s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 2974.8s of the 21423.3s of remaining time.\n",
      "\t-290.2216     = Validation score (-MAE)\n",
      "\t23.11   s     = Training runtime\n",
      "\t3.22    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoARIMA. Training for up to 3466.2s of the 21397.0s of remaining time.\n",
      "\t-232.5528     = Validation score (-MAE)\n",
      "\t247.15  s     = Training runtime\n",
      "\t138.75  s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 4082.2s of the 21011.1s of remaining time.\n",
      "\t-251.6819     = Validation score (-MAE)\n",
      "\t284.97  s     = Training runtime\n",
      "\t0.38    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 5031.4s of the 20725.7s of remaining time.\n",
      "\t-375.8097     = Validation score (-MAE)\n",
      "\t12.40   s     = Training runtime\n",
      "\t0.37    s     = Validation (prediction) runtime\n",
      "Training timeseries model DeepAR. Training for up to 6704.3s of the 20712.9s of remaining time.\n",
      "\t-218.4210     = Validation score (-MAE)\n",
      "\t492.01  s     = Training runtime\n",
      "\t4.74    s     = Validation (prediction) runtime\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 9808.1s of the 20216.1s of remaining time.\n",
      "\t-248.2469     = Validation score (-MAE)\n",
      "\t744.81  s     = Training runtime\n",
      "\t2.48    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 18868.8s of the 19468.8s of remaining time.\n",
      "\t-285.9413     = Validation score (-MAE)\n",
      "\t326.90  s     = Training runtime\n",
      "\t1.23    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'AutoARIMA': 0.22, 'DeepAR': 0.6, 'DirectTabular': 0.01, 'NPTS': 0.02, 'PatchTST': 0.01, 'RecursiveTabular': 0.13, 'TemporalFusionTransformer': 0.01}\n",
      "\t-204.4247     = Validation score (-MAE)\n",
      "\t13.59   s     = Training runtime\n",
      "\t149.94  s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'CrostonSBA', 'NPTS', 'AutoETS', 'DynamicOptimizedTheta', 'AutoARIMA', 'RecursiveTabular', 'DirectTabular', 'DeepAR', 'TemporalFusionTransformer', 'PatchTST', 'WeightedEnsemble']\n",
      "Total runtime: 2470.12 s\n",
      "Best model: WeightedEnsemble\n",
      "Best model score: -204.4247\n",
      "\tWARNING: refit_full functionality for TimeSeriesPredictor is experimental and is not yet supported by all models.\n",
      "Refitting models via `refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix '_FULL' and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `fit` call.\n",
      "Fitting model: SeasonalNaive_FULL | Skipping fit via cloning parent ...\n",
      "Fitting model: CrostonSBA_FULL | Skipping fit via cloning parent ...\n",
      "Fitting model: NPTS_FULL | Skipping fit via cloning parent ...\n",
      "Fitting model: AutoETS_FULL | Skipping fit via cloning parent ...\n",
      "Fitting model: DynamicOptimizedTheta_FULL | Skipping fit via cloning parent ...\n",
      "Fitting model: AutoARIMA_FULL | Skipping fit via cloning parent ...\n",
      "Fitting model: RecursiveTabular_FULL | Skipping fit via cloning parent ...\n",
      "Fitting model: DirectTabular_FULL | Skipping fit via cloning parent ...\n",
      "Fitting model: DeepAR_FULL | Skipping fit via cloning parent ...\n",
      "Fitting model: TemporalFusionTransformer_FULL | Skipping fit via cloning parent ...\n",
      "Fitting model: PatchTST_FULL | Skipping fit via cloning parent ...\n",
      "Fitting model: WeightedEnsemble_FULL | Skipping fit via cloning parent ...\n",
      "Refit complete. Models trained: ['SeasonalNaive_FULL', 'CrostonSBA_FULL', 'NPTS_FULL', 'AutoETS_FULL', 'DynamicOptimizedTheta_FULL', 'AutoARIMA_FULL', 'RecursiveTabular_FULL', 'DirectTabular_FULL', 'DeepAR_FULL', 'TemporalFusionTransformer_FULL', 'PatchTST_FULL', 'WeightedEnsemble_FULL']\n",
      "Total runtime: 0.92 s\n",
      "Updated best model to 'WeightedEnsemble_FULL' (Previously 'WeightedEnsemble'). AutoGluon will default to using 'WeightedEnsemble_FULL' for predict().\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.timeseries.predictor.TimeSeriesPredictor at 0x23a13213190>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.common import space\n",
    "\n",
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=3,\n",
    "    target=\"net_payment_count\",\n",
    "    eval_metric=\"MAE\",\n",
    "    freq='M',\n",
    "    quantile_levels=[0.3, 0.31, 0.32, 0.33, 0.34 ,0.35, 0.4, 0.5],\n",
    "#     known_covariates_names=[\"month\", \"year\"]\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    model_2020_df_up_data,\n",
    "    presets=\"best_quality\",\n",
    "    time_limit= 3600 * 6,\n",
    "    num_val_windows=4,\n",
    "    refit_every_n_windows=1,\n",
    "    refit_full=True,\n",
    "    # excluded_model_types=[\"CrostonSBA\", \"NPTS\", \"DirectTabular\", \n",
    "    #                      \"TemporalFusionTransformer\", \"PatchTST\"],\n",
    "    \n",
    "    # hyperparameters={\n",
    "    #   \"AutoARIMA\": {\"n_jobs\": 6},\n",
    "    # # #   \"SeasonalNaive\": {\"n_jobs\": 6},\n",
    "    # # #   \"Naive\": {\"n_jobs\": 6},\n",
    "    # #   \"AutoETS\": {\"n_jobs\": 6},\n",
    "    #   \"DynamicOptimizedTheta\": {\"n_jobs\": 6},\n",
    "    #   \"RecursiveTabular\": {\"n_jobs\": 6},\n",
    "    # #   \"AutoCES\": {\"n_jobs\": 6},\n",
    "    # # #   \"ADIDA\": {},\n",
    "    # # #   \"IMAPA\": {},\n",
    "    # # #   \"DLinear\": {},\n",
    "    # # #   \"SimpleFeedForward\": {},\n",
    "    #   \"DeepAR\": {\"n_jobs\": 6},\n",
    "    #     },\n",
    "    # hyperparameter_tune_kwargs={\n",
    "# #     \"num_trials\": 5,\n",
    "# #     \"scheduler\": \"local\",\n",
    "# #     \"searcher\": \"random\",\n",
    "#     \"n_jobs\": -1\n",
    "# },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.timeseries.utils.forecast import get_forecast_horizon_index_ts_dataframe\n",
    "\n",
    "future_index = get_forecast_horizon_index_ts_dataframe(model_2020_df_up_data, prediction_length=3)\n",
    "future_timestamps = future_index.get_level_values(\"timestamp\")\n",
    "known_covariates = add_date_features(pd.DataFrame(index=future_index), merged_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_up = predictor.predict(model_2020_df_up_data, known_covariates=known_covariates, model='WeightedEnsemble_FULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predictions_up.copy().reset_index()\n",
    "results['id'] = results['timestamp'].dt.strftime('%Y%m') + results['item_id']\n",
    "\n",
    "# Select the 'id' and 'mean' columns and rename 'mean' to 'net_payment_count'\n",
    "model_2020_up_sub = results[['id', '0.35']].rename(columns={'0.35': 'net_payment_count'})\n",
    "\n",
    "model_2020_up_sub.to_csv('model_2020_up_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "net_payment_count    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2020_up_sub.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2020_down_sub.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
